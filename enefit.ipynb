{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy import stats \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as py\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enefit = pd.read_csv(\"./predict-energy-behavior-of-prosumers/train.csv\")\n",
    "enefit[\"datetime\"] = pd.to_datetime(enefit[\"datetime\"])\n",
    "enefit[\"date\"] =  enefit[\"datetime\"].dt.date\n",
    "\n",
    "consumption = enefit[enefit[\"is_consumption\"]==1]\n",
    "consumption_mean = consumption.target.mean()\n",
    "consumption_daily = consumption.groupby(['date'])['target'].mean().reset_index()\n",
    "\n",
    "production = enefit[enefit[\"is_consumption\"]==0]\n",
    "production_mean = production.target.mean()\n",
    "production_daily = production.groupby(['date'])['target'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas = pd.read_csv(\"./predict-energy-behavior-of-prosumers/gas_prices.csv\")\n",
    "# gas.drop([\"origin_date\"],inplace=True,axis=1)\n",
    "gas[\"forecast_date\"] = pd.to_datetime(gas[\"forecast_date\"])\n",
    "\n",
    "daily_gas = gas.groupby(pd.Grouper(key=\"forecast_date\", freq='D')).mean() \n",
    "meanGasLow = gas.lowest_price_per_mwh.mean()\n",
    "meanGasHigh = gas.highest_price_per_mwh.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity = pd.read_csv(\"./predict-energy-behavior-of-prosumers/electricity_prices.csv\")\n",
    "# electricity.drop([\"origin_date\"],inplace=True,axis=1)\n",
    "electricity[\"forecast_date\"] = pd.to_datetime(electricity[\"forecast_date\"])\n",
    "\n",
    "daily_elec = electricity.groupby(pd.Grouper(key=\"forecast_date\", freq='D')).mean() \n",
    "meanElec = electricity.euros_per_mwh.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_weather = pd.read_csv(\"./predict-energy-behavior-of-prosumers/historical_weather.csv\")\n",
    "historical_weather[\"datetime\"] = pd.to_datetime(historical_weather[\"datetime\"])\n",
    "\n",
    "historical_weather_daily = historical_weather.groupby(pd.Grouper(key=\"datetime\", freq='D')).mean() \n",
    "historical_weather_meanTemp = historical_weather.temperature.mean()\n",
    "historical_weather_meanSolar = historical_weather.direct_solar_radiation.mean()\n",
    "historical_weather_meanShort = historical_weather.shortwave_radiation.mean()\n",
    "historical_weather_meanRain = historical_weather.rain.mean()\n",
    "historical_weather_meanSnow = historical_weather.snowfall.mean()\n",
    "historical_weather_meanWindspeed = historical_weather.windspeed_10m.mean()\n",
    "historical_weather_meanSurfacePressure = historical_weather.surface_pressure.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_weather = pd.read_csv(\"./predict-energy-behavior-of-prosumers/forecast_weather.csv\")\n",
    "forecast_weather[\"origin_datetime\"] = pd.to_datetime(forecast_weather[\"origin_datetime\"])\n",
    "\n",
    "forecast_weather_daily = forecast_weather.groupby(pd.Grouper(key=\"origin_datetime\", freq='D')).mean() \n",
    "forecast_weather_meanTemp = forecast_weather.temperature.mean()\n",
    "forecast_weather_meanSolar = forecast_weather.direct_solar_radiation.mean()\n",
    "forecast_weather_meanSnow = forecast_weather.snowfall.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "- Original file의 raw data 시각화하여 전반적인 데이터 파악"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consumption / Production\n",
    "- kaggle에서 예측하려고 하는 것은 'train.csv'의 에너지 사용량/생산량을 의미하는 'target' column\n",
    "- 'train_csv'의 'is_consumption' column을 통해 에너지의 생산/소비 구분\n",
    "- 실제 kaggle 에서는 hourly 예측이 목표이지만 먼저 daily로 data 탐색\n",
    "- 'train.csv'의 'target' column을 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(consumption, x=consumption.datetime, y=\"target\", title='Hourly Consumption Analysis')\n",
    "fig.update_traces(line_color='#FA163F')\n",
    "fig.update_layout(xaxis_title=\"Datetime\", yaxis_title=\"Consumption\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(consumption_daily, x=consumption_daily.date, y=\"target\", title='Daily Consumption Analysis')\n",
    "fig.add_hline(y=consumption_mean, line_dash=\"dot\", annotation_text=\"Average Consumption\", annotation_position=\"bottom right\")\n",
    "fig.update_traces(line_color='#FA163F')\n",
    "fig.update_layout(xaxis_title=\"Date\", yaxis_title=\"Consumption\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(production,x=production.datetime,y=\"target\", title='Hourly Production Analysis')\n",
    "fig.update_traces(line_color='#427D9D')\n",
    "fig.update_layout(xaxis_title=\"Date\", yaxis_title=\"Production\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(production_daily,x=production_daily.date,y=\"target\", title='Daily Production Analysis')\n",
    "fig.add_hline(y=production_mean, line_dash=\"dot\", annotation_text=\"Average Daily Production\", annotation_position=\"bottom right\")\n",
    "fig.update_traces(line_color='#427D9D')\n",
    "fig.update_layout(xaxis_title=\"Date\", yaxis_title=\"Production\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에너지 순소비량 = 소비량 - 생산량\n",
    "fig = px.area(consumption_daily[\"target\"]-production_daily[\"target\"], x=production_daily.index,y=\"target\", title='Daily Net Consumption (Consumption-Production) Analysis')\n",
    "fig.add_hline(y=(consumption_daily[\"target\"]-production_daily[\"target\"]).mean(), line_dash=\"dot\", annotation_text=\"Average Daily Net Consumption\", annotation_position=\"bottom right\")\n",
    "fig.update_traces(line_color='#EC8F5E')\n",
    "fig.update_layout(xaxis_title=\"Date\", yaxis_title=\"Net Consumption\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gas\n",
    "- 가스 가격은 실제 생산과 거래가 이루어지는 전날의 가격으로 구매하거나 판매\n",
    "- origin_date: 거래하기 전 날, 즉 가격이 형성되는 날짜\n",
    "- forecast_date: 실제 거래가 이루어지는 날"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(daily_gas, x=daily_gas.index, y=[\"lowest_price_per_mwh\",\"highest_price_per_mwh\"], title='Daily Price/MWh Analysis', color_discrete_map={\"lowest_price_per_mwh\": \"#EFB74F\", \"highest_price_per_mwh\": \"#247881\"})\n",
    "fig.add_hline(y=meanGasLow, line_dash=\"dot\", annotation_text=\"Average Low Price/MWh\", annotation_position=\"top right\")\n",
    "fig.add_hline(y=meanGasHigh, line_dash=\"dot\", annotation_text=\"Average High Price/MWh\", annotation_position=\"bottom right\")\n",
    "fig.update_layout(xaxis_title=\"Date\", yaxis_title=\"Euros/MWh\", legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electricity\n",
    "- 가스의 거래 방식과 같은 구조\n",
    "- 'origin_date'와 'forecast_date'도 같은 개념"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(daily_elec, x=daily_elec.index, y=[\"euros_per_mwh\"], title='Daily Price/MWh Analysis', color_discrete_map={\"euros_per_mwh\": \"#EFB74F\"})\n",
    "fig.add_hline(y=meanElec, line_dash=\"dot\", annotation_text=\"Average Price/MWh\", annotation_position=\"top right\")\n",
    "fig.update_layout(xaxis_title=\"Date\", yaxis_title=\"Euros/MWh\", legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical Weather\n",
    "- 날씨 관측 데이터\n",
    "- 미래의 날씨를 예보하는 것이 아닌 실제 기록된 데이터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(historical_weather_daily, x=historical_weather_daily.index, y=\"temperature\", title='Daily Historical Temperature Analysis')\n",
    "fig.add_hline(y=historical_weather_meanTemp, line_dash=\"dot\", annotation_text=\"Average Temperature\", annotation_position=\"bottom right\")\n",
    "fig.update_traces(line_color='#C59279')\n",
    "fig.update_layout(xaxis_title=\"Date\", yaxis_title=\"Temperature\", legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(historical_weather_daily, x=historical_weather_daily.index, y=[\"direct_solar_radiation\", \"shortwave_radiation\"], title='Daily Radiation Analysis', color_discrete_map={\"shortwave_radiation\": \"#6499E9\", \"direct_solar_radiation\": \"#C70A80\"})\n",
    "fig.add_hline(y=historical_weather_meanSolar, line_dash=\"dot\", annotation_text=\"Average Solar Radiation\", annotation_position=\"bottom right\")\n",
    "fig.add_hline(y=historical_weather_meanShort, line_dash=\"dot\", annotation_text=\"Average Shortwave Radiation\", annotation_position=\"top right\")\n",
    "fig.update_layout(xaxis_title=\"Date\", yaxis_title=\"Radiation Level\",legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(historical_weather_daily, x=historical_weather_daily.index, y=[\"windspeed_10m\"], title='Daily Windspeed Analysis', color_discrete_map={\"windspeed_10m\": \"#69C98D\"}, line_shape='spline')\n",
    "fig.add_hline(y=historical_weather_meanWindspeed, line_dash=\"dot\", annotation_text=\"Average Windspeed\", annotation_position=\"bottom right\")\n",
    "fig.update_layout(xaxis_title=\"Date\", yaxis_title=\"Windspeed (in m/s)\", legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(historical_weather_daily, x=historical_weather_daily.index, y=[\"surface_pressure\"], title='Daily Surface Pressure Analysis', color_discrete_map={\"surface_pressure\": \"#D61640\"}, line_shape='spline')\n",
    "fig.add_hline(y=historical_weather_meanSurfacePressure, line_dash=\"dot\", annotation_text=\"Average Surface Pressure\", annotation_position=\"bottom right\")\n",
    "fig.update_layout(xaxis_title=\"Date\", yaxis_title=\"Pressure (in Hectopascals)\",yaxis_range=[900,1100], legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Weather\n",
    "- 전날 기록되는 날씨 예보 데이터\n",
    "- origin_datetime: 예보 데이터가 만들어지는 기준 시각\n",
    "- forecast_datetime: 위 기준 시각에서 만들어지는 예보 데이터, 48시간 이후까지 예보 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(forecast_weather_daily, x=forecast_weather_daily.index, y=\"temperature\", title='Daily Forecast Temperature Analysis')\n",
    "fig.add_hline(y=forecast_weather_meanTemp, line_dash=\"dot\",annotation_text=\"Average Temperature\", annotation_position=\"bottom right\")\n",
    "fig.update_traces(line_color='#C59279')\n",
    "fig.update_layout(xaxis_title=\"Date\", yaxis_title=\"Temperature\", legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "- Kaggle에서는 'data_block_id'를 모든 file에 동일하게 부여\n",
    "- 데이터 병합에 사용하기에 가장 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should merge on 'data_block_id'\n",
    "print(enefit[['datetime','data_block_id']].head(3))\n",
    "print()\n",
    "print(gas[['origin_date','forecast_date','data_block_id']].head(3))\n",
    "print()\n",
    "print(electricity[['origin_date','forecast_date','data_block_id']].head(3))\n",
    "print()\n",
    "print(historical_weather[['datetime','data_block_id']].head(3))\n",
    "print()\n",
    "print(forecast_weather[['origin_datetime','forecast_datetime','data_block_id']].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enefit_daily = enefit.groupby([c for c in enefit.columns if c not in ['target', 'datetime', 'row_id', 'prediction_unit_id','date']])['target'].mean().reset_index()\n",
    "\n",
    "enefit_daily['target'] = stats.zscore(enefit_daily['target']) \n",
    "\n",
    "print(enefit_daily.shape)\n",
    "print(enefit_daily['data_block_id'].nunique())\n",
    "enefit_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas = pd.read_csv('./predict-energy-behavior-of-prosumers/gas_prices.csv')\n",
    "\n",
    "# gas_hourly = gas.copy()\n",
    "# gas_hourly[\"forecast_date\"] = pd.to_datetime(gas_hourly[\"forecast_date\"])\n",
    "# gas_hourly[\"origin_date\"] = pd.to_datetime(gas_hourly[\"origin_date\"])\n",
    "# gas_hourly = gas_hourly.set_index(\"forecast_date\").resample(\"H\").ffill().reset_index().rename({\"forecast_date\": \"forecast_datetime\"}, axis=1)\n",
    "\n",
    "gas = gas.drop(['forecast_date', 'origin_date'], axis=1)\n",
    "\n",
    "gas[['lowest_price_per_mwh', 'highest_price_per_mwh']] = stats.zscore(gas[['lowest_price_per_mwh', 'highest_price_per_mwh']]) \n",
    "\n",
    "gas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity = pd.read_csv(\"./predict-energy-behavior-of-prosumers/electricity_prices.csv\")\n",
    "electricity_daily = electricity.drop(['forecast_date', 'origin_date'], axis=1)\n",
    "electricity_daily = electricity_daily.groupby('data_block_id').mean().reset_index()\n",
    "\n",
    "electricity_daily['euros_per_mwh'] = stats.zscore(electricity_daily['euros_per_mwh']) \n",
    "\n",
    "electricity_daily.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_weather = pd.read_csv(\"./predict-energy-behavior-of-prosumers/forecast_weather.csv\")\n",
    "county_lat_lon = pd.read_csv('./predict-energy-behavior-of-prosumers/county_lon_lats.csv')\n",
    "\n",
    "# Extracting the necessary columns (longitude and latitude) from both dataframes\n",
    "weather_coords = forecast_weather[['longitude', 'latitude']].values\n",
    "county_coords = county_lat_lon[['longitude', 'latitude']].values\n",
    "\n",
    "# Creating a KDTree for efficient nearest neighbor search\n",
    "kd_tree = cKDTree(county_coords)\n",
    "\n",
    "# Finding the nearest neighbor for each point in weather_coords\n",
    "# The query method returns distances and indices of the nearest neighbors\n",
    "distances, indices = kd_tree.query(weather_coords)\n",
    "\n",
    "# Using the indices to map the 'county' values from _county_lon_lats_df to forecast_weather_df\n",
    "forecast_weather['county'] = county_lat_lon.loc[indices, 'county'].values\n",
    "\n",
    "# Now, performing the requested data manipulations\n",
    "# Removing specified columns\n",
    "forecast_weather = forecast_weather.drop(['latitude', 'longitude', 'origin_datetime', 'forecast_datetime'], axis=1)\n",
    "\n",
    "# Filtering out rows with 'hours_ahead' values from 1 to 24\n",
    "forecast_weather = forecast_weather[~forecast_weather['hours_ahead'].between(1, 24)]\n",
    "\n",
    "# Dropping the 'hours_ahead' column\n",
    "forecast_weather = forecast_weather.drop('hours_ahead', axis=1)\n",
    "\n",
    "# Grouping by all columns (except 'data_block_id') and calculating mean based on 'data_block_id'\n",
    "forecast_weather = forecast_weather.groupby(['data_block_id', 'county']).mean().reset_index()\n",
    "\n",
    "# Standardize of continuous features\n",
    "forecast_weather_columns = forecast_weather.columns.difference(['data_block_id','county'])\n",
    "forecast_weather[forecast_weather_columns] = stats.zscore(forecast_weather[forecast_weather_columns]) \n",
    "\n",
    "forecast_weather.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_weather = pd.read_csv(\"./predict-energy-behavior-of-prosumers/historical_weather.csv\")\n",
    "\n",
    "# Extracting the necessary columns (longitude and latitude) from both dataframes\n",
    "weather_coords = historical_weather[['longitude', 'latitude']].values\n",
    "county_coords = county_lat_lon[['longitude', 'latitude']].values\n",
    "\n",
    "# Creating a KDTree for efficient nearest neighbor search\n",
    "kd_tree = cKDTree(county_coords)\n",
    "\n",
    "# Finding the nearest neighbor for each point in weather_coords\n",
    "# The query method returns distances and indices of the nearest neighbors\n",
    "distances, indices = kd_tree.query(weather_coords)\n",
    "\n",
    "# Using the indices to map the 'county' values from county_lon_lats_df to forecast_weather_df\n",
    "historical_weather['county'] = county_lat_lon.loc[indices, 'county'].values\n",
    "\n",
    "# Now, performing the requested data manipulations\n",
    "# Removing specified columns\n",
    "historical_weather = historical_weather.drop(['latitude', 'longitude', 'datetime', ], axis=1)\n",
    "\n",
    "# Grouping by all columns (except 'data_block_id') and calculating mean based on 'data_block_id'\n",
    "historical_weather = historical_weather.groupby(['data_block_id', 'county']).mean().reset_index()\n",
    "\n",
    "# Standardize of continuous features\n",
    "historical_weather_columns = historical_weather.columns.difference(['data_block_id','county'])\n",
    "historical_weather[historical_weather_columns] = stats.zscore(historical_weather[historical_weather_columns]) \n",
    "\n",
    "historical_weather.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pd.read_csv('./predict-energy-behavior-of-prosumers/client.csv')\n",
    "\n",
    "# Standardize of continuous features\n",
    "client[['eic_count', 'installed_capacity']] = stats.zscore(client[['eic_count', 'installed_capacity']]) \n",
    "\n",
    "client.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜를 의미하는 'data_block_id'에 사용자를 의미하는 'prdiction_unit_id'를 기준으로 하는 dataframe 생성\n",
    "# 'country', 'is_business', 'product_type'은 사용자의 속성을 의미\n",
    "\n",
    "df = pd.merge(enefit_daily, gas, on='data_block_id', how='inner')\n",
    "df = pd.merge(df, electricity_daily, on='data_block_id', how='inner')\n",
    "df = pd.merge(df, forecast_weather, on=['data_block_id', 'county'], how='inner')\n",
    "df = pd.merge(df, historical_weather, on=['data_block_id', 'county'], how='inner')\n",
    "df = pd.merge(df, client, on=['data_block_id', 'product_type', 'county','is_business'], how='inner').drop('date', axis=1)\n",
    "# df = df.drop('data_block_id', axis=1)\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 속성별로 데이터 차이 구분\n",
    "\n",
    "# Creating plots for 'target' values changed by 'data_block_id', \n",
    "# with separate plots for different values of 'is_business', 'product_type', and 'county'.\n",
    "\n",
    "# Plot for 'target' values by 'data_block_id' for different 'is_business' values\n",
    "g = sns.FacetGrid(df, col=\"is_business\", height=4, aspect=1.5)\n",
    "g.map(sns.lineplot, \"data_block_id\", \"target\")\n",
    "g.set_titles(\"is_business = {col_name}\")\n",
    "g.set_axis_labels(\"Data Block ID\", \"Target Value\")\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle(\"Target Values by Data Block ID for Different is_business Values\")\n",
    "plt.show()\n",
    "\n",
    "# Plot for 'target' values by 'data_block_id' for different 'product_type' values\n",
    "g = sns.FacetGrid(df, col=\"product_type\", col_wrap=4, height=4, aspect=1)\n",
    "g.map(sns.lineplot, \"data_block_id\", \"target\")\n",
    "g.set_titles(\"product_type = {col_name}\")\n",
    "g.set_axis_labels(\"Data Block ID\", \"Target Value\")\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle(\"Target Values by Data Block ID for Different Product Types\")\n",
    "plt.show()\n",
    "\n",
    "# Plot for 'target' values by 'data_block_id' for different 'county' values\n",
    "g = sns.FacetGrid(df, col=\"county\", col_wrap=4, height=4, aspect=1)\n",
    "g.map(sns.lineplot, \"data_block_id\", \"target\")\n",
    "g.set_titles(\"county = {col_name}\")\n",
    "g.set_axis_labels(\"Data Block ID\", \"Target Value\")\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle(\"Target Values by Data Block ID for Different Counties\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the data to include only rows where 'is_consumption' is 1\n",
    "filtered_data = enefit[enefit['is_consumption'] == 1]\n",
    "\n",
    "# Grouping the data by 'prediction_unit_id' and 'date'\n",
    "grouped_data = filtered_data.groupby(['prediction_unit_id', 'date'])['target'].sum().reset_index()\n",
    "\n",
    "# Pivoting the data for plotting\n",
    "pivot_data = grouped_data.pivot(index='date', columns='prediction_unit_id', values='target')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.lineplot(data=pivot_data)\n",
    "plt.title('Target Value Changes Over Time by Prediction Unit ID (is_consumption = 1)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Target Value')\n",
    "plt.legend(title='Prediction Unit ID', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the top 2 'prediction_unit_id's with the highest average 'target' values\n",
    "top_prediction_unit_ids = filtered_data.groupby('prediction_unit_id')['target'].mean().nlargest(2).index\n",
    "\n",
    "# Excluding the top 2 'prediction_unit_id's from the filtered data\n",
    "excluded_data = filtered_data[~filtered_data['prediction_unit_id'].isin(top_prediction_unit_ids)]\n",
    "\n",
    "# Grouping the excluded data by 'prediction_unit_id' and 'date'\n",
    "grouped_excluded_data = excluded_data.groupby(['prediction_unit_id', 'date'])['target'].mean().reset_index()\n",
    "\n",
    "# Pivoting the data for plotting\n",
    "pivot_excluded_data = grouped_excluded_data.pivot(index='date', columns='prediction_unit_id', values='target')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.lineplot(data=pivot_excluded_data)\n",
    "plt.title('Target Value Changes Over Time (Excluding Top 2 Prediction Unit IDs)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Target Value')\n",
    "plt.legend(title='Prediction Unit ID', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values in the 'county', 'product_type', and 'data_block_id' columns\n",
    "unique_values = {\n",
    "    \"county\": df['county'].unique(),\n",
    "    \"product_type\": df['product_type'].unique()\n",
    "    }\n",
    "\n",
    "# Create dummy variables for 'county' and 'product_type'\n",
    "df_dummies_county = pd.get_dummies(df['county'], prefix='county', drop_first=True)\n",
    "df_dummies_product_type = pd.get_dummies(df['product_type'], prefix='product_type', drop_first=True)\n",
    "\n",
    "# Drop the original categorical columns from the dataframe\n",
    "df_dummy = df.drop(['county', 'product_type'], axis=1)\n",
    "\n",
    "# Concatenate the dummy variables with the original dataframe\n",
    "df_dummy = pd.concat([df, df_dummies_county, df_dummies_product_type], axis=1)\n",
    "\n",
    "# Define the dependent variable and independent variables\n",
    "y = df_dummy['target']\n",
    "X = df_dummy.drop(['target'], axis=1)  # Dropping 'Unnamed: 0' as it seems like an index\n",
    "\n",
    "# Adding a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())\n",
    "\n",
    "# Predicting on the filtered dataset\n",
    "y_hat = model.predict(X)\n",
    "\n",
    "# Calculating residuals\n",
    "residuals = y - y_hat\n",
    "\n",
    "# Performing a normality test on the residuals\n",
    "normality_test_result = stats.shapiro(residuals)\n",
    "\n",
    "# Calculating the model performance metrics\n",
    "rmse = mean_squared_error(y, y_hat) ** .5\n",
    "r2 = r2_score(y, y_hat)\n",
    "\n",
    "print('rmse:', rmse)\n",
    "print('r2:', r2)\n",
    "print('normality_test_result:', normality_test_result)\n",
    "\n",
    "# Plotting the residuals\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.scatter(y.index, residuals, s=20)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.title('Residual Plot')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Generating a Q-Q plot for the residuals\n",
    "plt.figure(figsize=(15, 6))\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "plt.xlabel('Theoretical Quantiles')\n",
    "plt.ylabel('Ordered Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the counties to select for one-hot encoding\n",
    "counties_to_select = ['county_0', 'county_2', 'county_11', 'county_13', 'county_14']\n",
    "\n",
    "# Create dummy variables for 'county' including only the specified counties\n",
    "df_dummies_county = pd.get_dummies(df['county'], prefix='county')\n",
    "df_dummies_product_type = pd.get_dummies(df['product_type'], prefix='product_type', drop_first=True)\n",
    "\n",
    "df_dummies_county = df_dummies_county[counties_to_select]\n",
    "\n",
    "# Concatenate the dummy variables with the original dataframe\n",
    "df_dummy_1 = pd.concat([df, df_dummies_county, df_dummies_product_type], axis=1)\n",
    "\n",
    "# Drop the original 'county' and 'product_type' columns\n",
    "df_dummy_1 = df_dummy_1.drop(['county', 'product_type'], axis=1)\n",
    "\n",
    "# Define the dependent variable and independent variables\n",
    "y = df_dummy_1['target']\n",
    "X = df_dummy_1.drop(['target'], axis=1)  # Dropping 'Unnamed: 0' as it seems like an index\n",
    "\n",
    "# Adding a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())\n",
    "\n",
    "# Predicting on the filtered dataset\n",
    "y_hat = model.predict(X)\n",
    "\n",
    "# Calculating residuals\n",
    "residuals = y - y_hat\n",
    "\n",
    "# Performing a normality test on the residuals\n",
    "normality_test_result = stats.shapiro(residuals)\n",
    "\n",
    "# Calculating the model performance metrics\n",
    "rmse = mean_squared_error(y, y_hat) ** .5\n",
    "r2 = r2_score(y, y_hat)\n",
    "\n",
    "print('rmse:', rmse)\n",
    "print('r2:', r2)\n",
    "print('normality_test_result:', normality_test_result)\n",
    "\n",
    "# Plotting the residuals\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.scatter(y.index, residuals, s=20)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.title('Residual Plot')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Generating a Q-Q plot for the residuals\n",
    "plt.figure(figsize=(15, 6))\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "plt.xlabel('Theoretical Quantiles')\n",
    "plt.ylabel('Ordered Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique counties\n",
    "unique_counties = df['county'].unique()\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(15, 6 * len(unique_counties)))\n",
    "\n",
    "for i, county in enumerate(unique_counties):\n",
    "    # Filter the dataframe for the current county\n",
    "    df_county = df[df['county'] == county]\n",
    "\n",
    "    # Create dummy variables for 'product_type'\n",
    "    df_dummies_product_type = pd.get_dummies(df_county['product_type'], prefix='product_type', drop_first=True)\n",
    "\n",
    "    # Drop the original categorical columns from the dataframe\n",
    "    df_county = df_county.drop(['county', 'product_type'], axis=1)\n",
    "\n",
    "    # Concatenate the dummy variables with the original dataframe\n",
    "    df_county = pd.concat([df_county, df_dummies_product_type], axis=1)\n",
    "\n",
    "    # Define the dependent variable and independent variables\n",
    "    y = df_county['target']\n",
    "    X = df_county.drop(['target'], axis=1)  # Dropping 'Unnamed: 0' as it seems like an index\n",
    "\n",
    "    # Adding a constant to the model (intercept)\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Fit the OLS model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    # Predicting on the filtered dataset\n",
    "    y_hat = model.predict(X)\n",
    "\n",
    "    # Calculating residuals\n",
    "    residuals = y - y_hat\n",
    "\n",
    "    # Plotting the residuals\n",
    "    plt.subplot(len(unique_counties), 1, i+1)\n",
    "    plt.scatter(y.index, residuals, s=20)\n",
    "    plt.axhline(y=0, color='red', linestyle='--')\n",
    "    plt.title(f'Residual Plot for County {county}')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to exclude 'county_11'\n",
    "df_filtered = df[df['county'] != 'county_11']\n",
    "\n",
    "# Create dummy variables for 'county' and 'product_type'\n",
    "df_dummies_county = pd.get_dummies(df_filtered['county'], prefix='county', drop_first=True)\n",
    "df_dummies_product_type = pd.get_dummies(df_filtered['product_type'], prefix='product_type', drop_first=True)\n",
    "\n",
    "# Drop the original categorical columns from the dataframe\n",
    "df_filtered = df_filtered.drop(['county', 'product_type'], axis=1)\n",
    "\n",
    "# Concatenate the dummy variables with the original dataframe\n",
    "df_filtered = pd.concat([df_filtered, df_dummies_county, df_dummies_product_type], axis=1)\n",
    "\n",
    "# Define the dependent variable and independent variables\n",
    "y = df_filtered['target']\n",
    "X = df_filtered.drop(['target'], axis=1)  # Dropping 'Unnamed: 0' as it seems like an index\n",
    "\n",
    "# Adding a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Predicting on the filtered dataset\n",
    "y_hat = model.predict(X)\n",
    "\n",
    "# Calculating residuals\n",
    "residuals = y - y_hat\n",
    "\n",
    "# Plotting the residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y.index, residuals, s=20)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.title('Residual Plot Excluding County_11')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to include only the desired county values\n",
    "df_filtered = df[df['county'].isin([0, 2, 11, 13, 14])]\n",
    "\n",
    "# Calculate the mean target value for each 'data_block_id'\n",
    "mean_target = df_filtered[df_filtered['county'] != 'other'].groupby('data_block_id')['target'].mean()\n",
    "\n",
    "# Replace the target values in the 'other' county column with the mean values\n",
    "df_filtered.loc[df_filtered['county'] == 'other', 'target'] = df_filtered.loc[df_filtered['county'] == 'other', 'data_block_id'].map(mean_target)\n",
    "\n",
    "# Perform one-hot encoding on the 'county' and 'product_type' columns\n",
    "df_new = pd.get_dummies(df_filtered, columns=['county', 'product_type'], drop_first=True)\n",
    "\n",
    "# Define the dependent variable and independent variables\n",
    "y = df_new['target']\n",
    "X = df_new.drop(['target'], axis=1)  # Dropping 'Unnamed: 0' as it seems like an index\n",
    "\n",
    "# Adding a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())\n",
    "\n",
    "# Predicting on the filtered dataset\n",
    "y_hat = model.predict(X)\n",
    "\n",
    "# Calculating residuals\n",
    "residuals = y - y_hat\n",
    "\n",
    "# Performing a normality test on the residuals\n",
    "normality_test_result = stats.shapiro(residuals)\n",
    "\n",
    "# Calculating the model performance metrics\n",
    "rmse = mean_squared_error(y, y_hat) ** .5\n",
    "r2 = r2_score(y, y_hat)\n",
    "\n",
    "print('rmse:', rmse)\n",
    "print('r2:', r2)\n",
    "print('normality_test_result:', normality_test_result)\n",
    "\n",
    "# Plotting the residuals\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.scatter(y.index, residuals, s=20)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.title('Residual Plot')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Generating a Q-Q plot for the residuals\n",
    "plt.figure(figsize=(15, 6))\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "plt.xlabel('Theoretical Quantiles')\n",
    "plt.ylabel('Ordered Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to include only the desired county values\n",
    "df_filtered = df[df['county'].isin([0, 2, 11, 13, 14])]\n",
    "\n",
    "# Perform one-hot encoding on the 'county' and 'product_type' columns\n",
    "df_new = pd.get_dummies(df_filtered, columns=['county', 'product_type'], drop_first=True)\n",
    "\n",
    "# Define the dependent variable and independent variables\n",
    "y = df_new['target']\n",
    "X = df_new.drop(['target'], axis=1)  # Dropping 'Unnamed: 0' as it seems like an index\n",
    "\n",
    "# Adding a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())\n",
    "\n",
    "# Predicting on the filtered dataset\n",
    "y_hat = model.predict(X)\n",
    "\n",
    "# Calculating residuals\n",
    "residuals = y - y_hat\n",
    "\n",
    "# Performing a normality test on the residuals\n",
    "normality_test_result = stats.shapiro(residuals)\n",
    "\n",
    "# Calculating the model performance metrics\n",
    "rmse = mean_squared_error(y, y_hat) ** .5\n",
    "r2 = r2_score(y, y_hat)\n",
    "\n",
    "print('rmse:', rmse)\n",
    "print('r2:', r2)\n",
    "print('normality_test_result:', normality_test_result)\n",
    "\n",
    "# Plotting the residuals\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.scatter(y.index, residuals, s=20)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.title('Residual Plot')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Generating a Q-Q plot for the residuals\n",
    "plt.figure(figsize=(15, 6))\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "plt.xlabel('Theoretical Quantiles')\n",
    "plt.ylabel('Ordered Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Assuming df_dummy is your one-hot encoded DataFrame\n",
    "y = df_dummy['target']\n",
    "X = df_dummy.drop(['target'], axis=1)\n",
    "\n",
    "# Adding a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Predicting on the dataset\n",
    "y_hat = model.predict(X)\n",
    "\n",
    "# Calculating residuals\n",
    "residuals = y - y_hat\n",
    "\n",
    "# Reshape the residuals to 2D array as required by the GaussianMixture model\n",
    "residuals_2d = residuals.values.reshape(-1, 1)\n",
    "\n",
    "# Fit a Gaussian Mixture Model with 3 components on the residuals\n",
    "gmm = GaussianMixture(n_components=3, random_state=42)\n",
    "gmm.fit(residuals_2d)\n",
    "\n",
    "# Predict the labels for the data points\n",
    "gmm_labels = gmm.predict(residuals_2d)\n",
    "\n",
    "# Convert the GMM labels to one-hot encoded features\n",
    "gmm_features = pd.get_dummies(gmm_labels, prefix='gmm', drop_first=True)\n",
    "\n",
    "# Add the GMM features to the dataset\n",
    "df_dummy = pd.concat([df_dummy, gmm_features], axis=1)\n",
    "\n",
    "# Plotting the residuals with different colors for each Gaussian component\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.scatter(y.index, residuals, c=gmm_labels, cmap='viridis', s=20)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.title('Residual Plot with Different Colors for Gaussian Components')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.colorbar(label='Gaussian Component')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Define the dependent variable and independent variables\n",
    "y = df_dummy['target']\n",
    "X = df_dummy.drop(['target'], axis=1)\n",
    "\n",
    "# Adding a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the OLS model with the GMM feature\n",
    "model_with_gmm = sm.OLS(y, X).fit()\n",
    "\n",
    "# Predicting on the dataset with the GMM feature\n",
    "y_hat_with_gmm = model_with_gmm.predict(X)\n",
    "\n",
    "# Calculating residuals with the GMM feature\n",
    "residuals_with_gmm = y - y_hat_with_gmm\n",
    "\n",
    "# Calculate the performance metrics with the GMM feature\n",
    "rmse_with_gmm = mean_squared_error(y, y_hat_with_gmm) ** .5\n",
    "r2_with_gmm = r2_score(y, y_hat_with_gmm)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Performance metrics with GMM feature:\")\n",
    "print(\"RMSE:\", rmse_with_gmm)\n",
    "print(\"R-squared:\", r2_with_gmm)\n",
    "\n",
    "# Plotting the residuals with different colors for each Gaussian component\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.scatter(y.index, residuals_with_gmm, c=gmm_labels, cmap='viridis', s=20)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.title('Residual Plot with GMM Included')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.colorbar(label='Gaussian Component')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
